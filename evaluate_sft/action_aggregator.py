"""
Aggregates action-specific statistics from evaluation results.

This script processes a JSON file generated by 'eval_pipeline.py', which contains
ground truth and predicted model outputs. It calculates:
1.  Distribution of unique actions observed in OOP and IP contexts for both
    ground truth and predictions.
2.  Accuracy of the model in predicting the most frequent OOP action.
3.  Accuracy of the model in predicting the IP action from the <ip_highest_freq_action> tag.

The results are saved to an output JSON file.
"""
import json
import argparse
import re
from collections import defaultdict
from typing import List, Dict, Any, Optional, Tuple

# Regex patterns (copied from eval_pipeline.py)
ACTION_LINE_PATTERN = re.compile(
    r"Action\s+(?P<name>[^:]+):\s+Avg\s+Frequency:\s+(?P<freq>[0-9]+\.?[0-9]*),\s+EV:\s+(?P<ev>[0-9.-]+)bb"
)
TAG_PATTERN = r"<{tag_name}(?:\s+action=\"(?P<action_attr>[^\"]*)\")?>(?P<content>.*?)</{tag_name}>"

def extract_tag_content(text: str, tag_name: str) -> Optional[Tuple[str, Optional[str]]]:
    """
    Extracts content and optional 'action' attribute from a custom tag.
    Returns (content, action_attribute) or None if tag not found.
    Handles nested tags by being non-greedy.
    (Copied from eval_pipeline.py)
    """
    pattern = TAG_PATTERN.format(tag_name=re.escape(tag_name))
    match = re.search(pattern, text, re.DOTALL)
    if match:
        return match.group("content").strip(), match.group("action_attr")
    return None

def parse_actions(action_block_content: str) -> List[Dict[str, Any]]:
    """
    Parses action lines from a block of text.
    (Copied from eval_pipeline.py)
    """
    actions = []
    if not action_block_content:
        return actions
    for line in action_block_content.strip().split('\n'):
        match = ACTION_LINE_PATTERN.match(line.strip())
        if match:
            actions.append({
                "name": match.group("name").strip(),
                "frequency": float(match.group("freq")),
                "ev": float(match.group("ev"))
            })
    return actions

def get_most_frequent_action(actions: List[Dict[str, Any]]) -> Optional[str]:
    """
    Determines the most frequent action from a list of parsed actions.
    (Copied from eval_pipeline.py)
    """
    if not actions:
        return None
    most_frequent = max(actions, key=lambda x: x["frequency"])
    return most_frequent["name"]

def _extract_percentage_from_action_list_style(name_lower: str) -> Optional[str]:
    """
    Extracts number from 'Action Name (X%)' style, given lowercase name.
    (Copied from eval_pipeline.py)
    """
    match = re.search(r'(\d+)%', name_lower)
    return match.group(1) if match else None

def _extract_percentage_from_attr_style(name_lower: str) -> Optional[str]:
    """
    Extracts number from 'keyword_X%pot' or 'keyword_X%' or '(X%)' style.
    (Copied from eval_pipeline.py)
    """
    match_keyword_style = re.search(r'(?:bet|raise|allin)_(\d+)%?', name_lower)
    if match_keyword_style:
        return match_keyword_style.group(1)
    match_paren_style = re.search(r'(\d+)%', name_lower)
    return match_paren_style.group(1) if match_paren_style else None

def are_actions_equivalent(action_from_list: Optional[str], action_from_attr: Optional[str]) -> bool:
    """
    Compares action names based on defined rules.
    (Copied from eval_pipeline.py)
    """
    if action_from_list is None or action_from_attr is None:
        return False

    s_list = action_from_list.lower()
    s_attr = action_from_attr.lower()

    if "check" in s_list and "check" in s_attr: return True
    if "allin" in s_list and "allin" in s_attr: return True
    if "fold" in s_list and "fold" in s_attr: return True

    if "bet" in s_list and "bet" in s_attr:
        num_list = _extract_percentage_from_action_list_style(s_list)
        num_attr = _extract_percentage_from_attr_style(s_attr)
        return bool(num_list and num_attr and num_list == num_attr)

    if "raise" in s_list and "raise" in s_attr:
        num_list = _extract_percentage_from_action_list_style(s_list)
        num_attr = _extract_percentage_from_attr_style(s_attr)
        return bool(num_list and num_attr and num_list == num_attr)
    
    return False

def parse_model_output(output_str: str) -> Dict[str, Any]:
    """
    Parses the model output string to extract key information.
    (Adapted from eval_pipeline.py to focus on necessary fields for this script)
    """
    parsed_data = {
        "oop_actions": [],
        "ip_actions_in_oop_expansion": [],
        "ip_highest_freq_action_tag": None,
        # Store errors for debugging if needed, though not directly used in aggregation logic
        "parsing_errors": [] 
    }

    # 1. <oop> (main)
    oop_block_match = extract_tag_content(output_str, "oop")
    if oop_block_match:
        oop_content, _ = oop_block_match
        parsed_data["oop_actions"] = parse_actions(oop_content)
        if not parsed_data["oop_actions"] and oop_content:
            parsed_data["parsing_errors"].append(f"Main <oop> block content not parsable: {oop_content[:100]}...")
    else:
        parsed_data["parsing_errors"].append("Main <oop> block not found.")

    # 2. <oop action="..."> for nested <ip>
    all_oop_tags = list(re.finditer(TAG_PATTERN.format(tag_name="oop"), output_str, re.DOTALL))
    expanded_oop_content_for_ip = None
    if len(all_oop_tags) > 1: # Assuming the second one is the expanded one
        match_obj = all_oop_tags[1]
        # Check if it actually has an action attribute to be sure it's the expanded one
        if match_obj.group("action_attr"):
             expanded_oop_content_for_ip = match_obj.group("content").strip()

    if expanded_oop_content_for_ip:
        ip_block_match = extract_tag_content(expanded_oop_content_for_ip, "ip")
        if ip_block_match:
            ip_content, _ = ip_block_match
            parsed_data["ip_actions_in_oop_expansion"] = parse_actions(ip_content)
            if not parsed_data["ip_actions_in_oop_expansion"] and ip_content:
                parsed_data["parsing_errors"].append(f"<ip> block content not parsable: {ip_content[:100]}...")
        else:
            parsed_data["parsing_errors"].append("<ip> block inside expanded <oop> not found.")
    elif len(all_oop_tags) == 1 and oop_block_match : # only main oop found
        parsed_data["parsing_errors"].append("Expanded <oop action=...> block (for <ip>) not found.")
    elif not oop_block_match: # no oop tags found at all
        parsed_data["parsing_errors"].append("No <oop> tags found, so no <ip> block either.")


    # 3. <ip_highest_freq_action>
    ip_highest_action_match = extract_tag_content(output_str, "ip_highest_freq_action")
    if ip_highest_action_match:
        parsed_data["ip_highest_freq_action_tag"] = ip_highest_action_match[0]
    else:
        parsed_data["parsing_errors"].append("<ip_highest_freq_action> tag not found.")
        
    return parsed_data

def aggregate_action_stats(input_file_path: str, output_file_path: str):
    """
    Aggregates action-specific statistics from the input JSON file
    and saves them to the output JSON file.
    """
    try:
        with open(input_file_path, 'r') as f:
            data = json.load(f)
    except FileNotFoundError:
        print(f"Error: Input file not found at {input_file_path}")
        return
    except json.JSONDecodeError:
        print(f"Error: Could not decode JSON from {input_file_path}")
        return

    if not isinstance(data, list):
        print("Error: Input JSON must be a list of objects.")
        return

    total_samples_in_file = len(data)
    if total_samples_in_file == 0:
        print("Input data is empty. No results to aggregate.")
        # Save an empty/minimal summary
        with open(output_file_path, 'w') as f:
            json.dump({"total_samples": 0, "message": "Input data was empty."}, f, indent=2)
        print(f"Empty summary saved to {output_file_path}")
        return

    # Initialize counters for new distribution logic (renaming for IP)
    gt_oop_hfa_dist_counts = defaultdict(int)
    gt_ip_hfa_dist_counts = defaultdict(int) # Renamed from gt_ip_tag_action_dist_counts
    pred_oop_hfa_dist_counts = defaultdict(int)
    pred_ip_hfa_dist_counts = defaultdict(int) # Renamed from pred_ip_tag_action_dist_counts

    # Initialize counters for accuracy
    # Key: GT action name, Value: {"ground_truth_count": N, "predicted_match_count": M}
    oop_action_accuracy_data = defaultdict(lambda: {"ground_truth_count": 0, "predicted_match_count": 0})
    ip_action_accuracy_data = defaultdict(lambda: {"ground_truth_count": 0, "predicted_match_count": 0})

    items_processed = 0
    items_skipped_missing_data = 0

    for i, item in enumerate(data):
        print(f"Processing item {i+1}/{total_samples_in_file}...")
        ground_truth_str = item.get("output")
        predicted_str = item.get("predicted_output")

        if ground_truth_str is None or predicted_str is None:
            items_skipped_missing_data += 1
            print(f"Warning: Item at index {i} is missing 'output' or 'predicted_output'. Skipping.")
            continue
        
        items_processed += 1

        gt_parsed = parse_model_output(ground_truth_str)
        pred_parsed = parse_model_output(predicted_str)

        # --- Action Distributions (Corrected Logic) ---
        # Ground Truth OOP Highest Frequency Action
        gt_oop_mfa_for_dist = get_most_frequent_action(gt_parsed.get("oop_actions", []))
        if gt_oop_mfa_for_dist:
            gt_oop_hfa_dist_counts[gt_oop_mfa_for_dist] += 1

        # Ground Truth IP Tag Action (now IP Highest Frequency Action for consistency)
        gt_ip_hfa_for_dist = gt_parsed.get("ip_highest_freq_action_tag")
        if gt_ip_hfa_for_dist and gt_ip_hfa_for_dist.strip():
            gt_ip_hfa_dist_counts[gt_ip_hfa_for_dist.strip()] += 1
        
        # Predicted OOP Highest Frequency Action
        pred_oop_mfa_for_dist = get_most_frequent_action(pred_parsed.get("oop_actions", []))
        if pred_oop_mfa_for_dist:
            pred_oop_hfa_dist_counts[pred_oop_mfa_for_dist] += 1

        # Predicted IP Tag Action (now IP Highest Frequency Action for consistency)
        pred_ip_hfa_for_dist = pred_parsed.get("ip_highest_freq_action_tag")
        if pred_ip_hfa_for_dist and pred_ip_hfa_for_dist.strip():
            pred_ip_hfa_dist_counts[pred_ip_hfa_for_dist.strip()] += 1

        # --- Action Accuracy (Logic remains the same) ---
        # OOP Most Frequent Action Accuracy
        gt_oop_mfa = get_most_frequent_action(gt_parsed.get("oop_actions", []))
        pred_oop_mfa = get_most_frequent_action(pred_parsed.get("oop_actions", []))

        if gt_oop_mfa:
            oop_action_accuracy_data[gt_oop_mfa]["ground_truth_count"] += 1
            if are_actions_equivalent(gt_oop_mfa, pred_oop_mfa):
                oop_action_accuracy_data[gt_oop_mfa]["predicted_match_count"] += 1
        
        # IP Highest Frequency Action Tag Accuracy
        gt_ip_hfa = gt_parsed.get("ip_highest_freq_action_tag")
        pred_ip_hfa = pred_parsed.get("ip_highest_freq_action_tag")

        if gt_ip_hfa and gt_ip_hfa.strip(): # Ensure it's not None or empty
            # Normalize whitespace for tag content, as it's free text.
            # However, are_actions_equivalent handles internal structure like "Bet (X%)"
            # So, simple strip should be fine before passing to are_actions_equivalent.
            norm_gt_ip_hfa = gt_ip_hfa.strip()
            ip_action_accuracy_data[norm_gt_ip_hfa]["ground_truth_count"] += 1
            if are_actions_equivalent(norm_gt_ip_hfa, pred_ip_hfa.strip() if pred_ip_hfa else None):
                ip_action_accuracy_data[norm_gt_ip_hfa]["predicted_match_count"] += 1
    
    # --- Prepare final results ---
    results = {
        "total_samples_in_file": total_samples_in_file,
        "processing_summary": {
            "items_processed": items_processed,
            "items_skipped_missing_data": items_skipped_missing_data
        },
        "ground_truth_distributions": {
            "oop_highest_frequency_action": {},
            "ip_highest_frequency_action": {} # Renamed from ip_tag_action
        },
        "predicted_output_distributions": {
            "oop_highest_frequency_action": {},
            "ip_highest_frequency_action": {} # Renamed from ip_tag_action
        },
        "oop_action_accuracy": {},
        "ip_action_accuracy": {}
    }

    # Calculate proportions for GT OOP HFA distribution
    total_gt_oop_hfa_actions_counted = sum(gt_oop_hfa_dist_counts.values())
    denominator_gt_oop_hfa = total_gt_oop_hfa_actions_counted if total_gt_oop_hfa_actions_counted > 0 else 1
    for name, count in gt_oop_hfa_dist_counts.items():
        results["ground_truth_distributions"]["oop_highest_frequency_action"][name] = {
            "count": count, "proportion": round(count / denominator_gt_oop_hfa, 4)
        }

    # Calculate proportions for GT IP Highest Frequency Action distribution
    total_gt_ip_hfa_actions_counted = sum(gt_ip_hfa_dist_counts.values())
    denominator_gt_ip_hfa = total_gt_ip_hfa_actions_counted if total_gt_ip_hfa_actions_counted > 0 else 1
    for name, count in gt_ip_hfa_dist_counts.items():
        results["ground_truth_distributions"]["ip_highest_frequency_action"][name] = {
            "count": count, "proportion": round(count / denominator_gt_ip_hfa, 4)
        }

    # Calculate proportions for Pred OOP HFA distribution
    total_pred_oop_hfa_actions_counted = sum(pred_oop_hfa_dist_counts.values())
    denominator_pred_oop_hfa = total_pred_oop_hfa_actions_counted if total_pred_oop_hfa_actions_counted > 0 else 1
    for name, count in pred_oop_hfa_dist_counts.items():
        results["predicted_output_distributions"]["oop_highest_frequency_action"][name] = {
            "count": count, "proportion": round(count / denominator_pred_oop_hfa, 4)
        }
    
    # Calculate proportions for Pred IP Highest Frequency Action distribution
    total_pred_ip_hfa_actions_counted = sum(pred_ip_hfa_dist_counts.values())
    denominator_pred_ip_hfa = total_pred_ip_hfa_actions_counted if total_pred_ip_hfa_actions_counted > 0 else 1
    for name, count in pred_ip_hfa_dist_counts.items():
        results["predicted_output_distributions"]["ip_highest_frequency_action"][name] = {
            "count": count, "proportion": round(count / denominator_pred_ip_hfa, 4)
        }

    # --- Group low proportion actions into "Other" category ---
    def group_low_proportion(dist_dict: Dict[str, Dict], threshold: float = 0.01) -> Dict[str, Dict]:
        if not dist_dict: # Handle case where the distribution might be empty
            return {}
        
        processed_dist = {}
        other_data = {"count": 0, "proportion": 0.0}
        has_other_category = False

        for name, data in dist_dict.items():
            if data["proportion"] < threshold:
                other_data["count"] += data["count"]
                other_data["proportion"] += data["proportion"]
                has_other_category = True
            else:
                processed_dist[name] = data
        
        if has_other_category:
            other_data["proportion"] = round(other_data["proportion"], 4) # Round summed proportion
            processed_dist["Other"] = other_data
        
        return processed_dist

    results["ground_truth_distributions"]["oop_highest_frequency_action"] = group_low_proportion(
        results["ground_truth_distributions"]["oop_highest_frequency_action"])
    results["ground_truth_distributions"]["ip_highest_frequency_action"] = group_low_proportion(
        results["ground_truth_distributions"]["ip_highest_frequency_action"])
    results["predicted_output_distributions"]["oop_highest_frequency_action"] = group_low_proportion(
        results["predicted_output_distributions"]["oop_highest_frequency_action"])
    results["predicted_output_distributions"]["ip_highest_frequency_action"] = group_low_proportion(
        results["predicted_output_distributions"]["ip_highest_frequency_action"])

    for action_name, data_counts in oop_action_accuracy_data.items():
        gt_count = data_counts["ground_truth_count"]
        match_count = data_counts["predicted_match_count"]
        results["oop_action_accuracy"][action_name] = {
            "ground_truth_highest_freq_count": gt_count,
            "predicted_match_count": match_count,
            "accuracy": round(match_count / gt_count, 4) if gt_count > 0 else 0
        }
    
    for action_name, data_counts in ip_action_accuracy_data.items():
        gt_count = data_counts["ground_truth_count"]
        match_count = data_counts["predicted_match_count"]
        results["ip_action_accuracy"][action_name] = {
            "ground_truth_tag_count": gt_count,
            "predicted_match_count": match_count,
            "accuracy": round(match_count / gt_count, 4) if gt_count > 0 else 0
        }

    # Save aggregated results
    try:
        with open(output_file_path, 'w') as f:
            json.dump(results, f, indent=2)
        print(f"Action aggregation complete. Results saved to {output_file_path}")
    except IOError:
        print(f"Error: Could not write results to {output_file_path}")

def main():
    parser = argparse.ArgumentParser(
        description="Aggregates action-specific statistics from SFT model evaluation results.",
        formatter_class=argparse.RawTextHelpFormatter
    )
    parser.add_argument(
        "input_file", 
        help="Path to the input JSON file (output from eval_pipeline.py)."
    )
    parser.add_argument(
        "output_file", 
        help="Path to save the aggregated action statistics JSON file."
    )
    
    args = parser.parse_args()
    
    print(f"Starting action aggregation from: {args.input_file}")
    print(f"Output will be saved to: {args.output_file}")
    aggregate_action_stats(args.input_file, args.output_file)

if __name__ == "__main__":
    main()

    '''
    To run this script (action_aggregator.py):
    python -m evaluate_sft.action_aggregator \
        <input_file_from_eval_pipeline.py> \
        <output_file_for_action_stats.json> 
    
    Example Usage:
    python -m evaluate_sft.action_aggregator \
        /home/xuandong/mnt/poker/internal-search-distillation-postflop-solver/evaluate_sft/20k_temp_exp/test_predictions.json \
        /home/xuandong/mnt/poker/internal-search-distillation-postflop-solver/evaluate_sft/20k_temp_exp/aggregated_action_stats.json
    ''' 